<!DOCTYPE html>
<html lang="ja">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta http-equiv="Content-Style-Type" content="text/css">
<meta http-equiv="Content-Script-Type" content="text/javascript">
<title>音声対話プログラム - 60256089 栗山明人</title>
</head>
<body>

<h1>課題：音声対話</h1>
<div id = "isActive"><span style="color:#000000">音声認識：オフ</span></div>

<div>
<button id="startButton">start</button>
<button id="stopButton">stop</button>
</div>

<div id="resultOutput"></div>

<style>
</style>

<script>
// 応答の定義（ハッシュ）    
var response = {
    "あなた,誰": ["私は音声対話プログラムです。"],
    "名前": ["私の名前はまだありません。"],
    "何歳": ["私はまだ生まれたばかりの0歳です。"],
    "こんにちは": ["こんにちは。"],
    "こんばんは": ["こんばんは。"],
    "おはよう": ["おはようございます。"],
    "おやすみ": ["おやすみなさい。"],
    "よろしく": ["よろしくお願いします。"],
    "元気": ["はい、私は元気です。"],
    "何月": [resp_Date()],
    "何日": [resp_Date()],
    "何時": [resp_Time()],
    "何分": [resp_Time()],
    "和歌山,天気": ["和歌山県の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/30/"],
    "大阪,天気": ["大阪府の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/27/"],
    "京都,天気": ["京都府の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/26/"],
    "奈良,天気": ["奈良県の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/29/"],
    "兵庫,天気": ["兵庫県の天気予報を表示します", "https://weather.yahoo.co.jp/weather/jp/28/"]
};

const startButton = document.querySelector('#startButton'); // 開始ボタン
const stopButton = document.querySelector('#stopButton'); // 停止ボタン
const resultOutput = document.querySelector('#resultOutput'); // 結果出力エリア
const isActive = document.querySelector('#isActive'); // 音声認識のオンオフ表示

if (!'SpeechSynthesisUtterance' in window) {
    alert("あなたのブラウザはSpeech Synthesis APIに未対応です。");
}
const tts = new SpeechSynthesisUtterance(); // TTSインスタンスを生成
//tts.text = textForm.value; // テキストを設定
tts.lang = "ja-JP"; // 言語(日本語)、英語の場合はen-US
tts.rate = 1.0; // 速度
tts.pitch = 1.0; // 声の高さ
tts.volume = 1.0; // 音量

SpeechRecognition = webkitSpeechRecognition || SpeechRecognition;
if (!'SpeechRecognition' in window) {
    alert("あなたのブラウザはSpeech Recognition APIに未対応です。");
}

const asr = new SpeechRecognition(); // ASRインスタンスを生成
asr.lang = "ja-JP"; // 言語（日本語）
asr.interimResults = true; // 途中結果出力をオン
asr.continuous = true; // 継続入力をオン

let output = ''; // 出力

// 日付の返答を返す
function resp_Date() {
    let now = new Date(); // 現在時刻を格納するオブジェクト
    let now_y = now.getMonth(); // 月
    let now_d = now.getDay(); // 日
    const resp = " 今日は " + now_y + " 月 " + now_d + " 日です。";
    return resp;
}

// 時刻の返答を返す
function resp_Time() {
    let now = new Date(); // 現在時刻を格納するオブジェクト
    let now_h = now.getMonth(); // 時
    let now_m = now.getDay(); // 分
    const resp = " 現在の時刻は " + now_h + " 時 " + now_m + " 分です。";
}

// 認識結果が出力されたときのイベントハンドラ
asr.onresult = function(event){
    let transcript = event.results[event.resultIndex][0].transcript; // 結果文字列

    let output_not_final = '';
    if (event.results[event.resultIndex].isFinal) { // 結果が確定（Final）のとき
	    asr.abort(); // 音声認識を停止
	    
        let answer;
        
        let keys = Object.keys(response);
        keys.forEach(function(key) {
            let flag = true;
            console.log(transcript);
            key.split(',').forEach(function(word) {              
                let pattern = new RegExp(word);
                let flag_test = pattern.test(transcript); // マッチしたらtrue, しなかったらfalse
                flag = flag && flag_test; // 両方trueならtrue
                console.log(pattern + '+' + ':' + flag_test);
                //flag = flag && new RegExp(word).test(transcript);
            });

            if (flag) {
		        answer = response[key][0];
                console.log(key + " : " + answer);

                if (typeof response[key][1] != 'undefined') {
                    window.open(response[key][1], '_blank');
                }
            }
        });

        if (typeof answer == 'undefined') {
	        answer = "すみません、よくわかりません。";
    	}
	
        output += transcript + ' => ' + answer + '<br>';

	    tts.text = answer;
	    // 再生が終了（end）ときのイベントハンドラ（終了したときに実行される）
	    tts.onend = function(event){
	        asr.start(); // 音声認識を再開
	    }

	    speechSynthesis.speak(tts); // 再生
    } else { // 結果がまだ未確定のとき
        output_not_final = '<span style="color:#dddddd;">' + transcript + '</span>';
    }
    resultOutput.innerHTML = output + output_not_final;
}

// 開始ボタンのイベントハンドラ
startButton.addEventListener('click', function() {
    asr.start();
    isActive.innerHTML = '<span style="color:#007fff">音声認識：オン</span>';
})

// 停止ボタンのイベントハンドラ
stopButton.addEventListener('click', function() {
    asr.abort();
    asr.stop();
    isActive.innerHTML = '<span style="color:#000000">音声認識：オフ</span>';
})
</script>

</body>
</html>
